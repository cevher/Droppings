{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff72f77-5040-4f48-bbd5-bb42d6189289",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c29516-0257-4b6d-a025-92efc433a34e",
   "metadata": {},
   "source": [
    "## Resizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4d20c71-a1c0-4d49-8963-e2edf8d9e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30904889-fccb-4dba-badf-c234941e98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('dotsResized')\n",
    "inputFolder = \"dots\"\n",
    "folderLen = len(inputFolder)\n",
    "for img in glob.glob(inputFolder +\"/*.jpg\"):\n",
    "    image = cv2.imread(img)\n",
    "    imgResized = cv2.resize(image, (256,256))\n",
    "    cv2.imwrite(\"dotsResized\" + img[folderLen:], imgResized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bedd069-7afd-4934-8d05-3da82b4f90eb",
   "metadata": {},
   "source": [
    "## Creating H5 File for train and valid dataset (%80 train, %20 valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d73c6e-6d0a-4886-8537-54bcc2f71a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A tool to download and preprocess data, and generate HDF5 file.\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from glob import glob\n",
    "from typing import List, Tuple\n",
    "\n",
    "import click\n",
    "import h5py\n",
    "import wget\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861ff40b-cd7d-490f-9ec5-d9ff430d5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5(dataset_name: str,\n",
    "                train_size: int,\n",
    "                valid_size: int,\n",
    "                img_size: Tuple[int, int],\n",
    "                in_channels: int=3):\n",
    "    \"\"\"\n",
    "    Create empty training and validation HDF5 files with placeholders\n",
    "    for images and labels (density maps).\n",
    "\n",
    "    Note:\n",
    "    Datasets are saved in [dataset_name]/train.h5 and [dataset_name]/valid.h5.\n",
    "    Existing files will be overwritten.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: used to create a folder for train.h5 and valid.h5\n",
    "        train_size: no. of training samples\n",
    "        valid_size: no. of validation samples\n",
    "        img_size: (width, height) of a single image / density map\n",
    "        in_channels: no. of channels of an input image\n",
    "\n",
    "    Returns:\n",
    "        A tuple of pointers to training and validation HDF5 files.\n",
    "    \"\"\"\n",
    "    # create output folder if it does not exist\n",
    "    os.makedirs(dataset_name, exist_ok=True)\n",
    "\n",
    "    # create HDF5 files: [dataset_name]/(train | valid).h5\n",
    "    train_h5 = h5py.File(os.path.join(dataset_name, 'train.h5'), 'w')\n",
    "    valid_h5 = h5py.File(os.path.join(dataset_name, 'valid.h5'), 'w')\n",
    "\n",
    "    # add two HDF5 datasets (images and labels) for each HDF5 file\n",
    "    for h5, size in ((train_h5, train_size), (valid_h5, valid_size)):\n",
    "        h5.create_dataset('images', (size, in_channels, *img_size))\n",
    "        h5.create_dataset('labels', (size, 1, *img_size))\n",
    "\n",
    "    return train_h5, valid_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b71fe6-5e12-4d15-9c31-10ce241d49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(label_info: np.array, image_shape: List[int]):\n",
    "    \"\"\"\n",
    "    Generate a density map based on objects positions.\n",
    "\n",
    "    Args:\n",
    "        label_info: (x, y) objects positions\n",
    "        image_shape: (width, height) of a density map to be generated\n",
    "\n",
    "    Returns:\n",
    "        A density map.\n",
    "    \"\"\"\n",
    "    # create an empty density map\n",
    "    label = np.zeros(image_shape, dtype=np.float32)\n",
    "\n",
    "    # loop over objects positions and marked them with 100 on a label\n",
    "    # note: *_ because some datasets contain more info except x, y coordinates\n",
    "    for x, y, *_ in label_info:\n",
    "        if y < image_shape[0] and x < image_shape[1]:\n",
    "            label[int(y)][int(x)] = 100\n",
    "\n",
    "    # apply a convolution with a Gaussian kernel\n",
    "    label = gaussian_filter(label, sigma=(1, 1), order=0)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24e77c5-6f9d-415b-ba6c-6bd7ecf1cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cell_data():\n",
    "    \"\"\"Generate HDF5 files for fluorescent cell dataset.\"\"\"\n",
    "    # download and extract dataset\n",
    "    # get_and_unzip(\n",
    "    #     'http://www.robots.ox.ac.uk/~vgg/research/counting/cells.zip',\n",
    "    #     location='cells'\n",
    "    # )\n",
    "    # create training and validation HDF5 files\n",
    "    train_h5, valid_h5 = create_hdf5('cell',\n",
    "                                     train_size=168,\n",
    "                                     valid_size=42,\n",
    "                                     img_size=(256, 256),\n",
    "                                     in_channels=3)\n",
    "\n",
    "    # get the list of all samples\n",
    "    # dataset name convention: XXXcell.png (image) XXXdots.png (label)\n",
    "    image_list = glob(os.path.join('cells', '*cell.*'))\n",
    "    image_list.sort()\n",
    "\n",
    "    def fill_h5(h5, images):\n",
    "        \"\"\"\n",
    "        Save images and labels in given HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            h5: HDF5 file\n",
    "            images: the list of images paths\n",
    "        \"\"\"\n",
    "        for i, img_path in enumerate(images):\n",
    "            # get label path\n",
    "            label_path = img_path.replace('cell.jpg', 'dots.jpg')\n",
    "            # get an image as numpy array\n",
    "            image = np.array(Image.open(img_path), dtype=np.float32) / 255\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "            # convert a label image into a density map: dataset provides labels\n",
    "            # in the form on an image with red dots placed in objects position\n",
    "\n",
    "            # load an RGB image\n",
    "            label = np.array(Image.open(label_path))\n",
    "            # make a one-channel label array with 100 in red dots positions\n",
    "            label = 100.0 * (label[:, :, 0] > 0)\n",
    "            # generate a density map by applying a Gaussian filter\n",
    "            label = gaussian_filter(label, sigma=(1, 1), order=0)\n",
    "\n",
    "            # save data to HDF5 file\n",
    "            h5['images'][i] = image\n",
    "            h5['labels'][i, 0] = label\n",
    "\n",
    "    # use first 150 samples for training and the last 50 for validation\n",
    "    fill_h5(train_h5, image_list[:168])\n",
    "    fill_h5(valid_h5, image_list[168:])\n",
    "\n",
    "    # close HDF5 files\n",
    "    train_h5.close()\n",
    "    valid_h5.close()\n",
    "\n",
    "    # cleanup\n",
    "    shutil.rmtree('cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9aae60-65e0-407a-ba66-56bbae0b9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_cell_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28e089-300d-43aa-afdb-33389459c6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
